{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac61cec7-504d-4e6d-9da4-7c2ad02b4602",
   "metadata": {},
   "source": [
    "# Pre-processing of NeuroImaging data for structural connectivity analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af46bf9f-dfeb-4b08-b0c8-546adc35ef0c",
   "metadata": {},
   "source": [
    "The pre-processing steps of MRI data are necessary steps. These steps are largely non-trivial and should follow a clear path which can grow exponentially complex depending on the modality you are working with. In this notebook you will find a guideline to pre-process T1 and diffusion images before computing tractograms and structural connectivity matrices. There are plenty of resources online to learn and stay up-to-date with the recommended guidelines (e.g., [MRtrix3 - DWI tutorial](https://mrtrix.readthedocs.io/en/latest/dwi_preprocessing/denoising.html) or [Andy's Brain Book](https://andysbrainbook.readthedocs.io/en/latest/index.html)). Otherwise, you can always rely on asking the community questions and/or doubts (e.g., [Neurstars](https://neurostars.org/)). Below you can find an example of how you would cite and explain to the scientific community the steps that were followed to pre-process your dataset for further analyses.\n",
    "\n",
    "*High resolution anatomical T1 weighted images were skull stripped [1], corrected for bias field inhomogeneities [2], registered to MNI space [3] and segmented into 5 tissue-type images [4]. Diffusion weighted images suffer from many artifacts all of which were appropriately corrected. Images were also skull-stripped [1], corrected for susceptibility-induced distortions [5], denoised [6], freed from Gibbs ringing artifacts [7] and corrected for eddy-currents and motion artifacts [8]. The preprocessed images were then co-registered to its corresponding anatomical template (already in MNI space) [3], resampled to a 1.5 mm3 voxel size and eventually corrected for bias field inhomogeneities [2]. After motion correction as well as registration to the MNI template, the B-matrix was appropriately rotated [9].*\n",
    "\n",
    "[1] M. Jenkinson, M. Pechaud, S. Smith and others, “BET2: MR-based estimation of brain, skull and scalp surfaces,” in Eleventh annual meeting of the organization for human brain mapping, 2005.\n",
    "\n",
    "[2] N. J. Tustison, B. B. Avants, P. A. Cook, Y. Zheng, A. Egan, P. A. Yushkevich and J. C. Gee, “N4ITK: improved N3 bias correction,” IEEE transactions on medical imaging, vol. 29, p. 1310–1320, 2010.\n",
    "\n",
    "[3] M. Jenkinson, P. Bannister, M. Brady and S. Smith, “Improved Optimization for the Robust and Accurate Linear Registration and Motion Correction of Brain Images,” vol. 17, pp. 825-841, 2002.\n",
    "\n",
    "[4] R. E. Smith, J.-D. Tournier, F. Calamante and A. Connelly, “Anatomically-constrained tractography: improved diffusion MRI streamlines tractography through effective use of anatomical information.,” NeuroImage, vol. 62, no. 3, p. 1924–1938, September 2012.\n",
    "\n",
    "[5] J. L. R. Andersson, S. Skare and J. Ashburner, “How to correct susceptibility distortions in spin-echo echo-planar images: application to diffusion tensor imaging.,” NeuroImage, vol. 20, no. 2, p. 870–888, October 2003.\n",
    "\n",
    "[6] J. Veraart, E. Fieremans and D. S. Novikov, “Diffusion MRI noise mapping using random matrix theory.,” Magnetic resonance in medicine, vol. 76, no. 5, p. 1582–1593, November 2016.\n",
    "\n",
    "[7] E. Kellner, B. Dhital, V. G. Kiselev and M. Reisert, “Gibbs-ringing artifact removal based on local subvoxel-shifts.,” Magnetic resonance in medicine, vol. 76, no. 5, p. 1574–1581, November 2016.\n",
    "\n",
    "[8] J. L. R. Andersson and S. N. Sotiropoulos, “An integrated approach to correction for off-resonance effects and subject movement in diffusion MR imaging.,” NeuroImage, vol. 125, p. 1063–1078, January 2016.\n",
    "\n",
    "[9] A. Leemans and D. K. Jones, “The B-matrix must be rotated when correcting for subject motion in DTI data.,” Magnetic resonance in medicine, vol. 61, no. 6, p. 1336–1349, June 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8efaaacf-40e8-4b9f-85a9-aef8ce44d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dea4be7",
   "metadata": {},
   "source": [
    "## Pre-processing of anatomical T1w MRI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c545eee",
   "metadata": {},
   "source": [
    "Eventhough it might seem a bit odd, we need to deal with structural data usually coming from T1 acquisitions. The reason is because delineating anatomical constraints on the diffusion data has been shown to improve the correspondance between real structural connectivity and the reconstructed by means of tractography (see ref. [4] in the introduction). There are several softwares avaialble for this, each one with its *pros* and *cons*. As usual, we provide an example code that follows the citation template shown in the introduction - although some slight differences exist due to software incompatibility. We start by first obtaining the bids directory with all the derivatives. Don't worry, we provided data in the Data4Labs already in the correct format. Otherwise, recall the exercises in Lab-1. \n",
    "\n",
    "For T1 data, [FSL](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSL) or [ANTs](https://stnava.github.io/ANTs/) are the safest options. [MRtrix3](https://mrtrix.readthedocs.io/en/latest/) offers some wrappers of them that come in handy if the goal is to use the pre-processed data for diffusion studies. Online containarized resources do exist that are specificallt designed for user friendliness, at the expense of freedom to operate [Brainlife](https://brainlife.io/about/). All of them are good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a10f8fb-6dec-45a4-9175-dedb88a17640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sub-CON01 in ses-control:\n",
      "---------------------------------------------\n",
      "Brain extracted succesfully\n",
      "Registered to MNI152 succesfully\n",
      "Segmented tissues succesfully\n",
      "Subcortical structures segmented succesfully\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Processing sub-CON02 in ses-control:\n",
      "---------------------------------------------\n",
      "Brain extracted succesfully\n",
      "Registered to MNI152 succesfully\n",
      "Segmented tissues succesfully\n",
      "Subcortical structures segmented succesfully\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Processing sub-CON06 in ses-control2:\n",
      "---------------------------------------------\n",
      "Brain extracted succesfully\n",
      "Registered to MNI152 succesfully\n",
      "Segmented tissues succesfully\n",
      "Subcortical structures segmented succesfully\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Processing sub-CON07 in ses-control:\n",
      "---------------------------------------------\n",
      "Brain extracted succesfully\n",
      "Registered to MNI152 succesfully\n",
      "Segmented tissues succesfully\n",
      "Subcortical structures segmented succesfully\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Processing sub-CON07 in ses-control2:\n",
      "---------------------------------------------\n",
      "Brain extracted succesfully\n",
      "Registered to MNI152 succesfully\n",
      "Segmented tissues succesfully\n",
      "Subcortical structures segmented succesfully\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "subjects = [\"01\", \"02\", \"06\" ,\"07\"]     # List of subjects in the dataset to pre-process\n",
    "sessions = [                            # Sessions per subject - Each subject might have different ones\n",
    "    [\"\"],\n",
    "    [\"\"],\n",
    "    [\"2\"],\n",
    "    [\"\",\"2\"]\n",
    "]\n",
    "# In this simple dataset we can manually annotate the subjects and sessions, but in a real case scenario \n",
    "#     you would use automated python or shell commands (i.e., \"find\" or \"os.listdir()\")\n",
    "\n",
    "for s, sub in enumerate(subjects):\n",
    "    for ss, ses in enumerate(sessions[s]):\n",
    "        # It is good practice to report summaries, updates, errors and logs\n",
    "        print(f\"Processing sub-CON{sub} in ses-control{ses}:\")\n",
    "        print(\"---------------------------------------------\")\n",
    "        \n",
    "        # Relevant directories per subject and session\n",
    "        bids_original = f\"../Data4Labs/BIDS-dir/sub-CON{sub}/ses-control{ses}/anat/\"\n",
    "        bids_derivatives = f\"../Data4Labs/BIDS-dir/derivatives/sub-CON{sub}/ses-control{ses}/anat/\"     \n",
    "        if not os.path.exists(bids_derivatives):\n",
    "            os.makedirs(bids_derivatives)\n",
    "        \n",
    "        # Original T1 file\n",
    "        file = os.path.join(bids_original, f\"sub-CON{sub}_ses-control{ses}_T1w.nii.gz\")\n",
    "        \n",
    "        # Brain Extraction Tool\n",
    "        masked_brain = os.path.join(bids_derivatives, f\"sub-CON{sub}_ses-control{ses}_T1w_brain.nii.gz\")\n",
    "        os.system(f\"bet {file} {masked_brain} -f .5 -g -.6\")\n",
    "        os.system(f\"bet {masked_brain} {masked_brain} -f .35 -m\")\n",
    "        print(\"Brain extracted succesfully\")\n",
    "\n",
    "        # Registration to template\n",
    "        reference = \"../Data4Labs/Utils/MNI152_T1_1mm_brain.nii.gz\"\n",
    "        registered = os.path.join(bids_derivatives, f\"sub-CON{sub}_ses-control{ses}_T1w_brain_space-MNI152.nii.gz\")\n",
    "        transformation = os.path.join(bids_derivatives, f\"sub-CON{sub}_ses-control{ses}_T1w_brain_matrix2MNI152.txt\")\n",
    "        os.system(f\"flirt -in {masked_brain} -ref {reference} -omat {transformation}\")\n",
    "        os.system(f\"flirt -in {masked_brain} -ref {reference} -out {registered} -applyxfm -init {transformation}\")\n",
    "        print(\"Registered to MNI152 succesfully\")\n",
    "\n",
    "        # Tissue segmentation\n",
    "        os.system(f\"fast -n 4 -I 25 -W 25 -H .25 {registered}\")\n",
    "        print(\"Segmented tissues succesfully\")\n",
    "\n",
    "        # We apply an extra layer of segmentation for subcortical gray matter structures\n",
    "        # TODO: first fsl https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FIRST/UserGuide\n",
    "        subcorticalGM = os.path.join(bids_derivatives, f\"sub-CON{sub}_ses-control{ses}_T1w_brain_space-MNI152_subcortical.nii.gz\")\n",
    "        os.system(f\"run_first_all -i {registered} -o {subcorticalGM}\")\n",
    "        os.rename(\n",
    "            f\"{bids_derivatives}sub-CON{sub}_ses-control{ses}_T1w_brain_space-MNI152_subcortical_all_fast_firstseg.nii.gz\",\n",
    "            f\"{bids_derivatives}sub-CON{sub}_ses-control{ses}_T1w_brain_space-MNI152_subcortex-GM.nii.gz\"\n",
    "        )\n",
    "        # Let's clean the output files that we won't be needing for this\n",
    "        to_delete = glob.glob(f\"{bids_derivatives}*_subcortical*\")\n",
    "        for f in to_delete:\n",
    "            try:\n",
    "                os.remove(f)\n",
    "            except:\n",
    "                shutil.rmtree(f)\n",
    "        to_delete = glob.glob(f\"{bids_derivatives}*_to_std_sub*\")\n",
    "        for f in to_delete:\n",
    "            os.remove(f)\n",
    "        print(\"Subcortical structures segmented succesfully\")\n",
    "        print(\"+++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "        print(\"+++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779691f1",
   "metadata": {},
   "source": [
    "In the case of DIPY the addition of subcortical structures to the anatomical mask is not needed. However, if you look carefully, you will see that subcortical regions (e.g., thalamus and/or striatum) are classified as a mixture of white and grey matter. It's ok, they are still good segmentations and \"fast\" is a good software. Furthermore, lotsof studies do not consider connectivity in the subcortex. Yet, a slightly more accurate pipeline is provided in MRtrix3by the command 5ttgen fsl (https://mrtrix.readthedocs.io/en/latest/reference/commands/5ttgen.html#ttgen-fsl). It implements a quite robust iteration over \"fast\" and \"first\" and combines the outputs into a single image. Hence, you need FSL and MRtrix3 to execute it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2328c89d",
   "metadata": {},
   "source": [
    "## Pre-processing of diffusion weighted images (dwi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b7745a",
   "metadata": {},
   "source": [
    "Diffusion MRI is slightly more intricate than anatomical scans. The physical phenomena behind the captured signal and further fiber reconstruction demand careful understanding of what is a true process happening inside the brain and what is induced by the operations during the acquisition. For that, we have no space to go into each detail that goes beyond a simple input and pre-processed output.\n",
    "\n",
    "In order to avoid you some crazy days in the search of the holy grail, we drop this piece of code to help you with the workflow, specific steps and information required by each one of them. Note how depending on the date that the data was acquired, some of the steps would not be applicable due to lack of information and acquisitions.\n",
    "\n",
    "A bit of a disclaimer... If some of this was useful for your purposes, consider acknowledging the work behind it:\n",
    "```\n",
    "@article{fmridtitumor2022,\n",
    "     title={Structural Reorganization Following a Brain Tumor: A Machine Learning Study Considering Desynchronized Functional Oscillations},\n",
    "     author={Falc{\\'o}-Roget, Joan and Sambataro, Fabio and Cacciola, Alberto and Crimi, Alessandro},\n",
    "     journal={bioRxiv},\n",
    "     pages={2022--11},\n",
    "     year={2022},\n",
    "     publisher={Cold Spring Harbor Laboratory}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01519cfa",
   "metadata": {},
   "source": [
    "### General workflow and steps to be followed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683f65d2",
   "metadata": {},
   "source": [
    "```\n",
    "import logging\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "from utils.paths import *\n",
    "from utils.steps import *\n",
    "from utils.acq_index_files import find_secondary_acquisitions\n",
    "\n",
    "def dwi_steps(f, output_directory, whole_path, subjectID, session, mri, name, acq, weight, extension, config):\n",
    "    \"\"\"\n",
    "    Performs the preprocessing steps in diffusion weighted images.\n",
    "    \"\"\"\n",
    "    output_directory = output_directory + 'co-registered/'\n",
    "    logging.info(f\" PreProcessing {subjectID} in session {session} with mri {mri}\")\n",
    "    steps = []\n",
    "\n",
    "    # Relevant paths\n",
    "    file_dir = output_directory+subjectID+'/'+session+'/'\n",
    "    mri_path = bids_tree(file_dir, mris=config[\"subjects\"][\"mris\"])[mri]\n",
    "    int_path, at_path = mri_path+'intermediate/', file_dir+'atlas/'\n",
    "    sec_path = mri_path+'intermediate/secondary/'\n",
    "    check_path(int_path)\n",
    "    check_path(sec_path)\n",
    "\n",
    "    ### Topup Susceptiility Artifacts Estimation ###\n",
    "    sec_files, available_secs = find_secondary_acquisitions(whole_path, subjectID, session, acq, weight)\n",
    "    if available_secs:\n",
    "        # Prepare data for topup and eddy\n",
    "        b0_vols, topup_data = prepare_topup(\n",
    "            input=f, tmp_dir=int_path, raw_dir=whole_path, sec_files=sec_files, skip=config[\"data\"][\"skip\"], vols=1\n",
    "        )\n",
    "        int_output, eddy_acq, eddy_index, bvecs, bvals = prepare_eddy(\n",
    "            input=f, tmp_dir=int_path, raw_dir=whole_path, sec_files=sec_files, merge=config[\"merge_acqs\"]\n",
    "            )\n",
    "\n",
    "        # TopUp can be performed only if there are at least one secondary acquisitions\n",
    "        unwarped, unwarped_mask = topup(input=b0_vols, output=sec_path+'topup', datain=topup_data, skip=config[\"data\"][\"skip\"])\n",
    "        steps.append(\"Top Up off-resonance field map\")\n",
    "\n",
    "        logging.info(f\" {subjectID} Suceptibility artifacts done\")\n",
    "    else:\n",
    "        # No susceptibility - then prepare for eddy\n",
    "        int_output, eddy_acq, eddy_index, bvecs, bvals = prepare_eddy(input=f, tmp_dir=int_path, raw_dir=whole_path)\n",
    "\n",
    "    # Brain Extraction \n",
    "    int_output, mask = brain_extraction(input=int_output, output=int_path+name+'_bet', skip=config[\"data\"][\"skip\"], method=config[\"dwi_be\"])\n",
    "    steps.append(\"Brain Extraction\")\n",
    "    logging.info(f\" {subjectID} Brain extraction done\")\n",
    "\n",
    "    # Denoise\n",
    "    int_output = MP_PCA_denoise(input=int_output, output=int_path+name+'_mppca', skip=config[\"data\"][\"skip\"], mask=mask)\n",
    "    steps.append(\"MP_PCA_denoise\")\n",
    "    logging.info(f\" {subjectID} Denoising done\")\n",
    "\n",
    "    # Gibbs artifacts\n",
    "    int_output = gibbs_unringing(input=int_output, output=int_path+name+'_gibbs', skip=config[\"data\"][\"skip\"])\n",
    "    steps.append(\"Gibbs_unringing\")\n",
    "    logging.info(f\" {subjectID} Gibbs artifacts removal done\")\n",
    "\n",
    "    # Eddy + Motion + Bmatrix Correction \n",
    "    tpd = sec_path+'topup' if available_secs else None\n",
    "    ed_mask = unwarped_mask if available_secs else mask\n",
    "    int_output, rotated_bvecs = eddy(\n",
    "        input=int_output, output=int_path+name+'_eddy', directory=sec_path, acq=eddy_acq, index=eddy_index,\n",
    "        bvecs=bvecs, bvals=bvals, mask=ed_mask, skip=config[\"data\"][\"skip\"], topup_data=tpd, cuda=config[\"eddy\"][\"cuda\"], version=config[\"eddy\"][\"version\"]\n",
    "    )\n",
    "    steps.append(\"Eddy-Motion-B correction\")\n",
    "    logging.info(f\" {subjectID} Eddy, Motion and Bmatrix correction done\")\n",
    "\n",
    "    # Remove eddy added background \n",
    "    int_output, mask = brain_extraction(input=int_output, output=int_path+name+'_eddy_bet', skip=config[\"data\"][\"skip\"], method=config[\"dwi_be\"])\n",
    "    steps.append(\"Brain Extraction\")\n",
    "    logging.info(f\" {subjectID} Eddy background removal done\")\n",
    "\n",
    "    # Registration // creation of reference+upsample\n",
    "    if config[\"reference\"] == 'dwi':\n",
    "        if config[\"reference\"] != \"atlas\":\n",
    "            check_path(at_path)\n",
    "        \n",
    "        # Copy bval and rename bvec to main derivatives folder \n",
    "        shutil.copyfile(rotated_bvecs, mri_path+name+'.bvec')\n",
    "        shutil.copyfile(whole_path+name+'.bval',mri_path+name+'.bval')\n",
    "\n",
    "        # Reference is DWI\n",
    "        int_output = upsample(input=int_output, output=mri_path+name, skip=config[\"data\"][\"skip\"], factor=config[\"vox_size\"][\"dwi\"])\n",
    "        upsample(input=mask, output=mri_path+name+'_mask', skip=config[\"data\"][\"skip\"], factor=config[\"vox_size\"][\"dwi\"])\n",
    "        steps.append(\"Upsampled to %s mm\" % config[\"vox_size\"][\"dwi\"])\n",
    "\n",
    "        reference_img = create_reference(int_output, output=at_path+name+'_ref', skip=config[\"data\"][\"skip\"])\n",
    "        steps.append(\"Created 3D DWI reference image\")\n",
    "    elif config[\"reference\"] == 'anat':\n",
    "        # Reference is Anat\n",
    "        reference_img = file_dir+'anat/'+subjectID+'_'+session+'_'+'T1w.nii.gz'\n",
    "        int_output, tr_matrix = register_to_reference(\n",
    "            input=int_output, output=int_path+name+'_reg', reference=reference_img, skip=config[\"data\"][\"skip\"], dim=4\n",
    "        )\n",
    "        reg_mask, _ = register_to_reference(\n",
    "            input=mask, output=int_path+name+'_reg_mask', reference=reference_img, skip=config[\"data\"][\"skip\"], matrix=tr_matrix\n",
    "        )\n",
    "        steps.append(\"Registered to Anat\")\n",
    "\n",
    "        # B-Matrix rotation\n",
    "        rotate_Bmatrix(bvecs=rotated_bvecs, bvals=bvals, output=mri_path+name, matrix=tr_matrix)\n",
    "        steps.append(\"BMatrix Reorientation\")\n",
    "\n",
    "        # Copy the transformation matrix to the output directory\n",
    "        shutil.copyfile(tr_matrix, mri_path+name+'_transform.txt') \n",
    "\n",
    "        # Upsample to dwi resolution\n",
    "        int_output = upsample(input=int_output, output=mri_path+name, skip=config[\"data\"][\"skip\"], factor=config[\"vox_size\"][\"dwi\"])\n",
    "        upsample(input=reg_mask, output=mri_path+name+'_mask', skip=config[\"data\"][\"skip\"], factor=config[\"vox_size\"][\"dwi\"])\n",
    "        steps.append(\"Upsampled to %s mm\" % config[\"vox_size\"][\"dwi\"])\n",
    "    elif config[\"reference\"] == 'atlas':\n",
    "        # TODO: Need further testing, for some reason the output is filled with zeros!\n",
    "\n",
    "        # Reference is Atlas\n",
    "        reference_img = config[\"atlas\"][\"REF\"]\n",
    "        int_output, tr_matrix = register_to_reference(\n",
    "            input=int_output, output=mri_path+name, reference=reference_img, skip=config[\"data\"][\"skip\"], dim=4\n",
    "        )\n",
    "        reg_mask, _ = register_to_reference(\n",
    "            input=mask, output=mri_path+name+'_mask', reference=reference_img, skip=config[\"data\"][\"skip\"], matrix=tr_matrix\n",
    "        )\n",
    "        steps.append(\"Registered to Atlas\")\n",
    "\n",
    "        # B-Matrix rotation\n",
    "        rotate_Bmatrix(bvecs=rotated_bvecs, bvals=bvals, output=mri_path+name, matrix=tr_matrix)\n",
    "        steps.append(\"BMatrix Reorientation\")\n",
    "        \n",
    "        # Copy the transformation matrix to the output directory\n",
    "        shutil.copyfile(tr_matrix, mri_path+name+'_transform.txt') \n",
    "\n",
    "        # Upsample to dwi resolution\n",
    "        int_output = upsample(int_output, output=mri_path+name, skip=False, factor=config[\"vox_size\"][\"dwi\"])\n",
    "        upsample(input=reg_mask, output=mri_path+name+'_mask', skip=False, factor=config[\"vox_size\"][\"dwi\"])\n",
    "        steps.append(\"Upsampled to %s mm\" % config[\"vox_size\"][\"dwi\"])\n",
    "    else:\n",
    "        raise ValueError(\"Reference image not recognized\")\n",
    "    logging.info(f\" {subjectID} Registration steps done\")\n",
    "\n",
    "\n",
    "    # Delete concatenated from original\n",
    "    os.remove(bvecs)\n",
    "    os.remove(bvals)\n",
    "\n",
    "    # Copy json to derivatives\n",
    "    shutil.copyfile(whole_path+name+'.json',mri_path+name+'.json')\n",
    "\n",
    "    # Keep intermediate\n",
    "    if not config[\"data\"][\"keep_intermediate\"]:\n",
    "        os.system(f\"rm -rf {int_path}\")\n",
    "\n",
    "    ### Output summary ###\n",
    "    logging.info(f\" Subject {subjectID} in session {session} with mri {mri} \\n with completed preprocessing steps: {', '.join(steps)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e58cc3",
   "metadata": {},
   "source": [
    "### Description and implementation of each step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdecef21",
   "metadata": {},
   "source": [
    "```\n",
    "import os\n",
    "from subprocess import Popen, STDOUT, PIPE\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "from utils.acq_index_files import acq_file, index_file\n",
    "from utils.paths import check_path\n",
    "\n",
    "from dipy.segment.mask import median_otsu \n",
    "from dipy.io.gradients import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table, reorient_bvecs\n",
    "from nibabel import load, Nifti1Image, save\n",
    "import numpy as np\n",
    "\n",
    "def brain_extraction(input, output, skip, method=None):\n",
    "    \"\"\"\n",
    "    Skull stripping using FSL's bet2 (for anatomical) and DIPY's median otsu (for diffusion).\n",
    "    \"\"\"\n",
    "    mask = output + '_mask.nii.gz'\n",
    "    if skip and os.path.exists(mask) and os.path.exists(output+'.nii.gz'):\n",
    "        return output+'.nii.gz', mask\n",
    "    else: \n",
    "        if 'T1w' in input:\n",
    "            os.system(\n",
    "                f\"bet2 {input} {output} -f 0.5 -g -.6\"\n",
    "            )\n",
    "            os.system(\n",
    "                f\"bet2 {output} {output} -f 0.35 -m\"\n",
    "            )\n",
    "        else:\n",
    "            if method == \"median_otsu\":\n",
    "                img = load(input)\n",
    "                data = img.get_fdata()\n",
    "                vol_idx = range(len(data[0,0,0,:])) if len(data.shape)==4 else None\n",
    "                bet_data, mask_data = median_otsu(data, vol_idx=vol_idx, numpass=5, median_radius=5, dilate=3, autocrop=False) \n",
    "                # Cropping the mask introduces dimensionality issues in eddy when using the unwarped masked b0 volume\n",
    "                save(Nifti1Image(bet_data, img.affine, img.header), output+'.nii.gz')\n",
    "                save(Nifti1Image(mask_data, img.affine, img.header), mask)\n",
    "            elif method == \"bet2\":\n",
    "                os.system( # Extract the first volume\n",
    "                    f\"fslroi {input} {output}_b0volume 0 1\"\n",
    "                )\n",
    "                os.system( # Mask the first volume\n",
    "                    f\"bet2 {output}_b0volume {output} -f 0.19 -m\"\n",
    "                )\n",
    "                os.system( # Apply the mask to all the volumes\n",
    "                    f\"fslmaths {input} -mas {mask} {output}\"\n",
    "                )\n",
    "            elif method is None:\n",
    "                print(\"--- No brain extraction method is provided ---\")\n",
    "            else:\n",
    "                raise ValueError(\"Brain Extraction method not implemented\")\n",
    "        return output+'.nii.gz', mask\n",
    "\n",
    "def MP_PCA_denoise(input, output, mask, skip):\n",
    "    \"\"\"\n",
    "    Marchenko-Pasteur PCA denoising using MRtrix3.\n",
    "    \"\"\"\n",
    "    if skip and os.path.exists(output+'.nii.gz'):\n",
    "        return output+'.nii.gz' \n",
    "    else:\n",
    "        os.system(\n",
    "            f\"dwidenoise {input} {output}'.nii.gz' -mask {mask} -force -quiet\"\n",
    "        )\n",
    "        return output+'.nii.gz' \n",
    "\n",
    "def gibbs_unringing(input, output, skip):\n",
    "    \"\"\"\n",
    "    Removal of Gibbs ringing artifacts using MRtrix3.\n",
    "    \"\"\"\n",
    "    if skip and os.path.exists(output+'.nii.gz'):\n",
    "        return output+'.nii.gz' \n",
    "    else:\n",
    "        os.system(\n",
    "            f\"mrdegibbs {input} {output}'.nii.gz' -force -quiet\"\n",
    "        )\n",
    "        return output+'.nii.gz' \n",
    "\n",
    "def register_to_reference(input, output, skip, reference, matrix=None, dim=3):\n",
    "    \"\"\"\n",
    "    #TODO: Add description\n",
    "    \"\"\"\n",
    "    if skip and os.path.exists(output+'.nii.gz'):\n",
    "        return output+'.nii.gz', output + '_transform.txt'\n",
    "    else:        \n",
    "        if dim == 3:\n",
    "            if matrix is None: # Find the linear transformation\n",
    "                transform_mat = output + '_transform.txt'\n",
    "                os.system(\n",
    "                    f\"flirt -in {input} -ref {reference} -out {output} -omat {transform_mat}\"\n",
    "                )\n",
    "                return output+'.nii.gz', transform_mat\n",
    "            else: # Apply the transformation\n",
    "                os.system(\n",
    "                    f\" flirt -in {input} -ref {reference} -out {output} -applyxfm -init {matrix}\"\n",
    "                )\n",
    "                return output+'.nii.gz', matrix\n",
    "        elif dim == 4:\n",
    "            if matrix is None: # Find the linear transformation\n",
    "                # It is assumed that the 4D image has been corrected for motion artifacts so all slices are coregistered!\n",
    "                tempdir = 'tmp-reg_' + output.split('/')[-1] + '/' #+output.split('/')[-4]+'/'\n",
    "                check_path(tempdir)\n",
    "                # Split allthe volumes into separate 3D files\n",
    "                os.system(\n",
    "                    f\"fslsplit {input} {tempdir} -t\"\n",
    "                )\n",
    "                transform_mat = output + '_transform.txt'\n",
    "                # Find the transformation with the first volume\n",
    "                os.system(\n",
    "                        f\"flirt -in {tempdir}'0000.nii.gz' -ref {reference} -out {tempdir}'0000.nii.gz' -omat {transform_mat}\"\n",
    "                    )\n",
    "                # Apply the transformation to the rest of the volumes\n",
    "                for vol in os.listdir(tempdir):\n",
    "                    if vol != '0000.nii.gz':\n",
    "                        os.system(\n",
    "                            f\" flirt -in {tempdir+vol} -ref {reference} -out {tempdir+vol} -applyxfm -init {transform_mat}\"\n",
    "                        )\n",
    "                # Merge all the volumes\n",
    "                os.system(\n",
    "                    f\"fslmerge -t {output} {tempdir}*.nii.gz\"\n",
    "                )\n",
    "                # Remove the temporary directory\n",
    "                os.system(\n",
    "                    f\"rm -rf {tempdir}\"\n",
    "                )\n",
    "                return output+'.nii.gz', transform_mat\n",
    "            else: #Apply the transformation\n",
    "                os.system(\n",
    "                    f\" flirt -in {input} -ref {reference} -out {output} -applyxfm -init {matrix}\"\n",
    "                )\n",
    "                return output+'.nii.gz', matrix\n",
    "        else:\n",
    "            raise ValueError('Dimension must be either 3 or 4')\n",
    "\n",
    "def bias_correction(input, output, skip, mask):\n",
    "    \"\"\"\n",
    "    Bias correction using N4 ants Algorithm.\n",
    "    \"\"\"\n",
    "    if skip and os.path.exists(output+'.nii.gz'):\n",
    "        return output+'.nii.gz'\n",
    "    else:\n",
    "        os.system( \n",
    "            f\"N4BiasFieldCorrection -i {input} -o {output}'.nii.gz' -d 3 -x {mask} -r\"\n",
    "        )\n",
    "        return output+'.nii.gz'\n",
    "\n",
    "def upsample(input, output, skip, factor=1.5):\n",
    "    \"\"\"\n",
    "    MRtrix3 upsampmling image to increase/decrease resolution.\n",
    "    \"\"\"\n",
    "    if skip and os.path.exists(output+'.nii.gz'):\n",
    "        return output+'.nii.gz'\n",
    "    else:\n",
    "        os.system( \n",
    "            f\"mrgrid {input} regrid {output}'.nii.gz' -force -quiet -voxel {factor}\"\n",
    "        )\n",
    "        return output+'.nii.gz'\n",
    "\n",
    "def create_reference(input, output, skip):\n",
    "    \"\"\"\n",
    "    Create a template image for registration. Useful for registering to dwis, since anatomical\n",
    "        and atlases are already 3D images.\n",
    "    \"\"\"\n",
    "    if skip and os.path.exists(output+'.nii.gz'):\n",
    "        return output+'.nii.gz'\n",
    "    else:\n",
    "        os.system(\n",
    "             f\"fslroi {input} {output} 0 1\"\n",
    "            )\n",
    "        return output+'.nii.gz'\n",
    "def extract_b0s(inputs, output, vols=None):\n",
    "    \"\"\"\n",
    "    Extract the b0 volumes from a DWI image.\n",
    "    Returns the number of b0 volumes extracted.\n",
    "    Saves the b0 volumes in the directory specified.\n",
    "    Options: Extract the specified number of b0 values if vols is not None\n",
    "    \"\"\"\n",
    "    # Extract all b0 volumes\n",
    "    os.system(\n",
    "        f\"dwiextract {inputs[0]} {output} -bzero -fslgrad {inputs[2]} {inputs[1]} -force -quiet\"\n",
    "    )\n",
    "    # Keep the specified number of b0 volumes\n",
    "    if vols is not None:\n",
    "        os.system(\n",
    "            f\"mrconvert {output} {output} -coord 3 0:{vols-1} -force -quiet\"\n",
    "        )\n",
    "    # Report the final number of volumes extracted\n",
    "    message = Popen(f\"fslnvols {output}\", shell=True, stdout=PIPE).stdout.read()\n",
    "    Nvolumes = int(str(message).removeprefix('b\\'').removesuffix('\\'').removesuffix('\\\\n').split('\\\\n')[0])\n",
    "    return output, Nvolumes\n",
    "\n",
    "def prepare_topup(input, tmp_dir, sec_files, raw_dir, skip, vols=None):\n",
    "    \"\"\"\n",
    "    Prepare the images and files to be used in the topup step.\n",
    "    ###\n",
    "    # TODO: Improve what is said below\n",
    "    Here it is assumed that all the acquisitions are co-registered.\n",
    "        Might not be exactly true, but for these datasets it approximately holds.\n",
    "        The fact that this is not exactly true will cause a WARNING whehn merging the volumes\n",
    "        from different acquisitions.\n",
    "    ####    \n",
    "    \"\"\"\n",
    "    output = tmp_dir+input.split('.')[0].split('/')[-1]+'_b0vols'\n",
    "    if skip and os.path.exists(output+'.nii.gz') and os.path.exists(tmp_dir+'topup_data.txt'):\n",
    "        return output+'.nii.gz', tmp_dir+'topup_data.txt'\n",
    "    else:\n",
    "        # List of main files in the scheme\n",
    "        main_file = input.split('.')[0]  \n",
    "        main_files = [main_file+'.nii.gz', main_file+'.bval', main_file+'.bvec', main_file+'.json']\n",
    "        ### These two lines are useful if and only if a bet has been run at the very begining of the pipeline\n",
    "        #origin_name = raw_dir+'_'.join(input.split('.')[0].split('/')[-1].split('_')[:-1])\n",
    "        #main_files = [main_file+'.nii.gz', origin_name+'.bval', origin_name+'.bvec', origin_name+'.json']\n",
    "\n",
    "        # Extract b0 volumes from main file\n",
    "        jsons, suffix = [], '_b0s'\n",
    "        _, Nvs = extract_b0s(main_files, tmp_dir+'main'+suffix+'.nii.gz', vols=vols)\n",
    "        for i in range(Nvs):\n",
    "            jsons.append(main_files[3]) # append the jsons as many times a b0s\n",
    "\n",
    "        # Extract b0 volumes from secondary files\n",
    "        for i in range(len(sec_files)):\n",
    "            _, Nvs = extract_b0s(sec_files[i], tmp_dir+'sec'+str(i)+suffix+'.nii.gz', vols=vols)\n",
    "            for j in range(Nvs):\n",
    "                jsons.append(sec_files[i][3]) # append the jsons as many times a b0s\n",
    "\n",
    "        # Merge the b0 files\n",
    "        os.system(\n",
    "            f\"fslmerge -t {output} {tmp_dir}*{suffix}.nii.gz\"\n",
    "        )\n",
    "        os.system(\n",
    "            f\"rm {tmp_dir}*{suffix}.nii.gz\"\n",
    "        )\n",
    "        # Create the acqparams file for the --datain option in topu up\n",
    "        acq_file(jsons, tmp_dir+'topup_data.txt')\n",
    "        return output+'.nii.gz', tmp_dir+'topup_data.txt'\n",
    "\n",
    "        \n",
    "def topup(input, output, datain, skip):\n",
    "    \"\"\"\n",
    "    https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/topup/TopupUsersGuide\n",
    "    Runs topup fsl command to estimate the off-ressonance field.\n",
    "    Additionally it performs a brain extraction on the unwarped b0 volumes to output a mask for eddy.\n",
    "    This function needs prepare_topup to be run first to run topup on the bo volumes from all the acquisitions.\n",
    "    Returns the unwarped b0 volumes and the mask estimated from them to pass as input to eddy (suggested in FSL wiki).\n",
    "    \"\"\"\n",
    "    if skip and os.path.exists(output+'_movpar.txt') and os.path.exists(output+'_fieldcoef.nii.gz') and os.path.exists(output+'_unwarped.nii.gz'):\n",
    "        return output+'_unwarped.nii.gz', output+'_unwarped_mask.nii.gz'\n",
    "    else:\n",
    "        os.system(\n",
    "            f\"topup --imain={input} --datain={datain} --out={output} --iout={output}_unwarped\"\n",
    "        )\n",
    "        os.system(\n",
    "            f\"fslmaths {output}_unwarped -Tmean {output}_unwarped\"\n",
    "        )\n",
    "        b0s_unwarped, b0s_unwarped_mask = brain_extraction(input=output+'_unwarped.nii.gz', output=output+'_unwarped', skip=False, method=\"bet2\")\n",
    "        os.system(\n",
    "            f\"rm {'/'.join(datain.split('/')[:-1])}/*.topup_log\"\n",
    "        )\n",
    "        return b0s_unwarped, b0s_unwarped_mask\n",
    "\n",
    "def concatenate_gradients(bvals, bvecs, output):\n",
    "    \"\"\"\n",
    "    Concatenate bvals and bvecs from different acquisitions into a single file.\n",
    "    \"\"\"\n",
    "    cat_bvals = '_'.join(output.split('_')[:-1])+'_concat.bval'\n",
    "    cat_bvecs = '_'.join(output.split('_')[:-1])+'_concat.bvec'\n",
    "\n",
    "    # Read and concatenate bvals and bvecs\n",
    "    bval_lines, bvec_lines = '', ['', '', '']\n",
    "    for i, j in zip(bvals, bvecs):\n",
    "        with open(i, 'r') as bval_table:\n",
    "            current = bval_table.readlines()[0].strip()\n",
    "            bval_lines = bval_lines + current + ' ' \n",
    "        with open(j, 'r') as bvec_table:\n",
    "            current = bvec_table.readlines()\n",
    "            bvec_lines[0] = bvec_lines[0] + current[0].strip() + ' '\n",
    "            bvec_lines[1] = bvec_lines[1] + current[1].strip() + ' ' \n",
    "            bvec_lines[2] = bvec_lines[2] + current[2].strip() + ' ' \n",
    "    \n",
    "    # Write the concatenated bvals and bvecs\n",
    "    with open(cat_bvals, 'w') as bval_table:\n",
    "        bval_table.write(bval_lines)\n",
    "    with open(cat_bvecs, 'w') as bvec_table:\n",
    "        bvec_table.write('\\n'.join(bvec_lines))\n",
    "    return cat_bvecs, cat_bvals\n",
    "\n",
    "def prepare_eddy(input, tmp_dir, raw_dir, sec_files=None, merge=None):\n",
    "    \"\"\"\n",
    "    Prepares the images and files to be used in the eddy step.\n",
    "    Based on the configuration and the secondary acquisitions,\n",
    "        it will merge everythin sequentially and the index file\n",
    "        will be created accordingly. Feel free to merge with other schemes.\n",
    "\n",
    "    ###\n",
    "    # TODO: Improve what is said below\n",
    "    Here it is assumed that all the acquisitions are co-registered.\n",
    "        Might not be exactly true, but for these datasets it approximately holds.\n",
    "        The fact that this is not exactly true will cause a WARNING whehn merging the volumes\n",
    "        from different acquisitions.\n",
    "    ####\n",
    "    \"\"\"\n",
    "    eddy_acq = tmp_dir+'eddy_acq.txt'\n",
    "    eddy_index = tmp_dir+'eddy_ind.txt'\n",
    "\n",
    "    # List of main files in the scheme\n",
    "    main_file = input.split('.')[0]    \n",
    "    files = [[main_file+'.nii.gz', main_file+'.bval', main_file+'.bvec', main_file+'.json']]\n",
    "    ### These two lines are useful if and only if a bet has been run at the very begining of the pipeline\n",
    "    #origin_name = raw_dir+'_'.join(input.split('.')[0].split('/')[-1].split('_')[:-1])\n",
    "    #files = [[main_file+'.nii.gz', origin_name+'.bval', origin_name+'.bvec', origin_name+'.json']]\n",
    "\n",
    "    # Merge files if specified\n",
    "    if merge and sec_files is not None:\n",
    "        merged_file = tmp_dir+'merged_acquisitions.nii.gz'\n",
    "        os.system(f\"cp {input} {merged_file}\")\n",
    "        for i in range(len(sec_files)):\n",
    "            files.append(sec_files[i])\n",
    "            os.system(\n",
    "                f\"fslmerge -t {merged_file} {merged_file} {sec_files[i][0]}\"\n",
    "            )\n",
    "    else:\n",
    "        merged_file = input\n",
    "\n",
    "    # Create the acquisition and index parameters file\n",
    "    jsons, niis = [files[i][-1] for i in range(len(files))], [files[i][0] for i in range(len(files))]\n",
    "    bvals, bvecs = [files[i][1] for i in range(len(files))], [files[i][2] for i in range(len(files))]\n",
    "    acq_file(jsons, eddy_acq)\n",
    "    index_file(niis, eddy_index)\n",
    "    cat_bvecs, cat_bvals = concatenate_gradients(bvals, bvecs, main_file)\n",
    "    return merged_file, eddy_acq, eddy_index, cat_bvecs, cat_bvals\n",
    "\n",
    "\n",
    "def eddy(input, output, directory, acq, index, bvecs, bvals, mask, skip, topup_data=None, cuda=False, version=None):\n",
    "    \"\"\"\n",
    "    https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddy/UsersGuide\n",
    "    Runs eddy, motion and b-matrix correction according to previous steps (prepare_topup, topup, prepare_eddy).\n",
    "    cuda: controls which version of eddy is used\n",
    "    \"\"\"\n",
    "    basename = directory + 'eddy_output'\n",
    "    if skip and os.path.exists(output+'.nii.gz') and os.path.exists(output+'.bvec'):\n",
    "        return output+'.nii.gz', output+'.bvec'\n",
    "    else:\n",
    "        ed_type = 'cuda'+str(version) if cuda else 'openmp'\n",
    "        if topup_data is None:\n",
    "            os.system(\n",
    "                f\"eddy_{ed_type} --imain={input} --mask={mask} --acqp={acq} --index={index} --bvecs={bvecs} --bvals={bvals} --out={basename}\"\n",
    "            )\n",
    "        else:\n",
    "            os.system(\n",
    "                f\"eddy_{ed_type} --imain={input} --mask={mask} --acqp={acq} --index={index} --bvecs={bvecs} --bvals={bvals} \\\n",
    "                --topup={topup_data} --out={basename}\" \n",
    "            )\n",
    "\n",
    "        # Filtering and renaming the important output files\n",
    "        Path(basename+'.nii.gz').rename(output+'.nii.gz')\n",
    "        Path(basename+'.eddy_rotated_bvecs').rename(output+'.bvec')\n",
    "        return output+'.nii.gz', output+'.bvec'\n",
    "\n",
    "def rotate_Bmatrix(bvecs, bvals, output, matrix):\n",
    "    \"\"\"\n",
    "    Rotates the b-matrix after the diffusion data has been 'moved' to the reference image.\n",
    "    It assumes that all volumes are corrected for motion artifacts and are co-registered;\n",
    "        therefore, the same transformation (rotation) matrix is applied to all b-vectors.\n",
    "    \"\"\"\n",
    "    # Bvals are not rotated\n",
    "    shutil.copyfile(bvals, output+'.bval')\n",
    "\n",
    "    # Read and rotate non-zeros bvecs\n",
    "    b_vals, b_vecs = read_bvals_bvecs(bvals, bvecs)\n",
    "    gtab = gradient_table(b_vals, b_vecs)\n",
    "    vols = gtab.bvals.shape[0]\n",
    "    v_trans, trans = np.loadtxt(matrix), list()\n",
    "    for v in range(vols):\n",
    "        if not gtab.b0s_mask[v]:\n",
    "            trans.append(v_trans)\n",
    "    gtab_corr = reorient_bvecs(gtab, trans)\n",
    "    np.savetxt(output+'.bvec', gtab_corr.bvecs.T)\n",
    "    return output+'.bvec', output+'.bval'\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
